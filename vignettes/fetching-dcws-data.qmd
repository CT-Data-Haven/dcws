---
title: "Fetching DCWS data"
description: Using the dcws package to get & analyze DCWS data
vignette: >
  %\VignetteIndexEntry{Fetching DCWS data}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
knitr:
    opts_chunk:
        comment: "#>"
        collapse: true
execute:
    warning: false
    message: false
    echo: true
fig-dpi: 150
fig-width: 6
---

This package has a dataset of all the data extracted from all (or at least most) the crosstabs for every DataHaven Community Wellbeing Survey wave, a total of `r nrow(dcws::cws_full_data)` files. It's all been cleaned up so that names, categories, and groups should be standardized to match across every location and year, and should be the same in the weights as in the data tables themselves. Every data point has its corresponding question text and code. 

When it's all combined and unnested, there are a few million rows of data, and no one needs all of that. Instead, use the function `fetch_cws` to pull out just the data you need, whether that's just one location across multiple years, multiple locations, a single question, or whatever.

Here are some pretty common examples of how we might work with DCWS data using this package, `cwi`, and some tidyverse. I'll mostly use some of the more straightforward questions that we ask every year, with Greater New Haven as an example because I know most of our demographic groups are available.

```{r}
#| label: libs
#| message: false
library(dplyr)
library(dcws)
library(forcats)
```

A common thing we'll present is a question represented as a single number (percent responding "yes", percent responding "strongly agree" or "somewhat agree", etc.) for the state, the region, a couple groups within that region, and large towns in the region. For this, I'll use named arguments for the year and categories of respondents, plus some of the open-ended filtering. I'll start out looking at food insecurity, since it's a simple yes or no. Since I'm doing this a couple times, I'll write a (pretty crappy) function. 


```{r}
#| label: functions
calc_food <- function(data) {
    data |>
        # get order that makes sense for this subset
        # mutate(group = fct_inorder(fct_drop(group))) |>
        cwi::sub_nonanswers() |> # remove don't know/refused & rescale values
        filter(
            group != "Other race",
            response == "Yes"
        ) |> # other race is only available in 2015
        select(span, name, category, group, value) |>
        mutate(value = round(value, digits = 2))
}
```

## Analysis

### One question, one year, few categories

```{r }
#| label: food1
food_21 <- fetch_cws(grepl("Have there been times .+ food", question),
    .name = "Greater New Haven", .category = c("Total", "Race/Ethnicity", "Gender"),
    .year = 2021, .unnest = TRUE
) |>
    calc_food()

knitr::kable(food_21)
```


### One question, several years, one location


```{r }
#| label: food2
food_trend <- fetch_cws(grepl("Have there been times .+ food", question),
    .name = "Greater New Haven", .category = c("Total", "Race/Ethnicity", "Gender"),
    .unnest = TRUE
) |>
    calc_food()

knitr::kable(food_trend)
```



### One question, one year, compare groups and locations

I want just the location-wide values for towns in Greater New Haven, or by race for Greater New Haven. I could do this filtering inside `fetch_cws` if I wanted to dig into the nested data with `purrr`, but I don't, so I'll just be a little redundant.

```{r }
#| label: food3
food_towns <- fetch_cws(grepl("Have there been times .+ food", question),
    .name = c("Greater New Haven", cwi::regions$`Greater New Haven`),
    .year = 2021, .unnest = TRUE
) |>
    filter((name == "Greater New Haven" & category %in% c("Total", "Race/Ethnicity")) |
        (group %in% cwi::regions$`Greater New Haven`)) |>
    calc_food() |>
    mutate(category = as_factor(ifelse(name == "Greater New Haven",
        as.character(category),
        "By town"
    )))

knitr::kable(food_towns)
```

### Several questions with same responses

Usually I like to analyze questions separately because they might not have the same set of responses, but for a bank of related questions you can do them all at once. In 2020 we added a question about trust in several types of institutions. I can't remember the codes for them but they all have "trust" in the question text. Using the `cws_codebook` dataset, I can look up what those codes were by pattern-matching.

```{r }
#| label: codebook
cws_codebook |>
    filter(grepl("How much trust", question)) |>
    filter(year == 2024) |>
    distinct(year, code, question)
```

Oh duh, the codes are all "TRUST" and then a letter!

The responses for these questions are a great deal, a fair amount, not very much, or none at all. I'm going to collapse great deal and fair amount into one, then present just that. Each question has the same beginning text, then at the end names the institution being asked about.

```{r }
#| label: trust1
trust_insts <- fetch_cws(grepl("^TRUST[A-Z]$", code),
    .name = "Greater New Haven", .year = 2021,
    .category = c("Total", "Age"), .unnest = TRUE
) |>
    mutate(
        response = fct_collapse(response, trust = c("A great deal", "A fair amount")),
        question = stringr::str_extract(question, "([\\w\\s]+)$") |>
            trimws() |>
            as_factor(),
        group = fct_inorder(fct_drop(group))
    ) |>
    group_by(category, group, question, response) |>
    summarise(value = sum(value)) |>
    cwi::sub_nonanswers() |>
    filter(response == "trust") |>
    mutate(value = round(value, digits = 2)) |>
    ungroup()

trust_insts |>
    tidyr::pivot_wider(id_cols = group, names_from = question) |>
    knitr::kable()
```

Lots of ways you could chop this data up now that you've got several groups and several questions together.

### Comparing to the state

All the crosstabs include Connecticut total values to compare to. The script that extracts all the crosstab data includes these, because they're sometimes useful: most of the tables and charts we publish of survey data for one location includes state values. The benefit is that if you want, say, Greater New Haven data, you don't have to do anything special to also have Connecticut totals. However, if you pull data for multiple locations, this would be annoyingly redundant. So I've added an argument `.drop_ct` that defaults to true, in which case Connecticut values from other locations' crosstabs are dropped before your data are returned.

With `.drop_ct = TRUE` (the default):

```{r}
#| label: drop-ct1
fetch_cws(code == "Q1",
    .year = 2021, .name = "Greater New Haven",
    .category = c("Total", "Gender"), .unnest = TRUE
) |>
    distinct(year, name, category, group)
```

With `.drop_ct = FALSE`:

```{r}
#| label: drop-ct2
fetch_cws(code == "Q1",
    .year = 2021, .name = "Greater New Haven",
    .category = c("Total", "Gender"), .unnest = TRUE, .drop_ct = FALSE
) |>
    distinct(year, name, category, group)
```

## Weights

The crosstabs each have a table of survey weights for each group, either as a standalone section at the bottom of the Excel spreadsheet or as a couple rows at the top of each question. `read_weights` now works with either of these formats; for the latter, the weights are taken from the first question (always the satisfied with your area question, which every participant receives). Just like preparing this package meant extracting all the data, there's also a stash of all the weights from all the files. These are useful for operations like collapsing multiple small groups into larger ones, usually income brackets or other groupings that may not be consistent between years or locations otherwise.

There's a function for getting weights on their own, with most of the same arguments as for getting data...

```{r }
#| label: wts1
head(fetch_wts(.year = 2021, .name = "Greater New Haven", .unnest = TRUE))
```

...or you can just use the `.add_wts` argument in `fetch_cws` to do this for you. You can also use `cwi::collapse_n_wt` to help with the calculation, but basically you're collapsing several levels, then getting weighted means.

One reason for doing this is that locations might have different income brackets depending on sample size, and we've moved toward using larger income brackets in the latest wave of the survey. So in addition to sample size, you might also collapse groups so you can compare across locations or years.

For example, check out how obnoxious this is:

```{r}
#| label: why-collapse
satisfied_area <- fetch_cws(grepl("satisfied with the city", question),
    .name = c("Connecticut", "Greater New Haven", "New Haven"),
    .unnest = TRUE, .category = c("Total", "Income")
)

satisfied_area |>
    filter(category == "Income") |>
    distinct(year, name, group) |>
    mutate(value = "x", id = paste(name, year)) |>
    tidyr::pivot_wider(
        id_cols = group,
        names_from = id,
        values_from = value,
        names_sort = TRUE,
        values_fill = ""
    ) |>
    arrange(group) |>
    knitr::kable()
```

Yikes

So you'll probably want to collapse some of those, like so:

```{r }
#| label: wts2
asthma18 <- fetch_cws(question == "Asthma",
    .year = 2018, .name = "Greater New Haven",
    .category = c("Total", "Income", "Race/Ethnicity"), .add_wts = TRUE, .unnest = TRUE
) |>
    cwi::collapse_n_wt(year:response,
        .lvls = list(
            "<$30K" = c("<$15K", "$15K-$30K"),
            "$30K-$100K" = c("$30K-$50K", "$50K-$75K", "$75K-$100K"),
            "$100K+" = c("$100K-$200K", "$200K+")
        )
    ) |>
    cwi::sub_nonanswers() |>
    mutate(value = round(value, digits = 2)) |>
    filter(response == "Yes")

knitr::kable(asthma18)
```

## Single year vs pooled years

One thing we added with the 2024 survey was a set of crosstabs for multiple years, pooled together and weighted accordingly. For small locations or groups with small sample sizes, this lets us get more granularity than we would have for a single year. So far 2024 is the only year/endyear this applies to, but presumably future survey waves will have this available as well. 

Usually your argument for `year` will be a single number, the year the survey was carried out. Pooled crosstabs are labeled with the endpoints, so crosstabs made up of surveys between 2015 and 2024 will be labeled `"2015_2024"`. When you call `fetch_cws`, there are now 2 year-related columns: a numeric one, `year`, with the last year of the crosstabs, and a character one, `span`, with the range of years included. For crosstabs of only 2024 data, both will say `2024`, but for crosstabs of 2015-2024 data, the year will be `2024` and the span will be `2015_2024`. If you want single-year data, give the year as a single numeric year; if you want pooled data, give the year in this `"{start_year}_{end_year}"` format.

```{r}
#| label: pool1
fetch_cws(
    code == "Q1",
    .year = "2015_2024",
    .name = "New Haven",
    .category = "Age"
)
```

If you want both single and pooled data (you probably don't), you can utilize the filtering done in the `...` argument instead, as they'll both have an endyear of 2024:

```{r}
#| label: pool2
fetch_cws(
    year == 2024,
    code == "Q1",
    .name = "New Haven",
    .category = "Age"
)
```

## Output

That's it! Usually I'll save a bunch of related analyses into lists of data frames, and then write those out to rds files for easy loading.
